Docker Commands
---------------

docker run redis
docker run busybox echo Hi there
docker create busybox ping google.com
docker start -a <hash-value>
docker system prune 
docker ps --all
docker ps 
docker logs <container-id>
docker stop <container-id> [SIGTERM]
docker kill <container-id> [SIGKILL]
docker exec -it <container-id> redis-cli
docker run -it busybox sh [open up the shell]


Docker File -> Docker Client -> Docker Server -> Usable Image

Creating a Docker File
----------------------
> Specify a base image
> Run some commands to install additional programs
> Specify a command to run on container startup

Dockerfile
----------
# Use an existing image as a base
FROM alpine

# Download and install a dependency
RUN apk add --update redis
RUN apk add --update gcc


# Tell the image what to do when it starts as a container
CMD ["redis-server"]

DOCKER BUILD
------------
docker build .

Docker Build & Tagging an image
-------------------------------
docker build -t sauravr/redis:latest .


"alpine" version is the most basic version of the image.
FROM node:14-alpine


When you are building an image, none of the files inside of your project directory right here are available inside the container by default. They are all a hundred percent sectioned off, completely segmented out, they are not at all available, and you cannot assume that any of these files are available unless you specifically allow it inside of your docker file.So as my guess, that's exactly what we're going to do. We're going to add in one line of configuration to our docker file to make sure that both our index.js file and package.json file are available inside the container.


COPY ./ COPY./


# Specify a base image
FROM node:14-alpine

# Install some dependencies
COPY ./ ./
RUN npm install

# Default Commands
CMD ["npm", "start"]


Docker RUN with PORT-MAPPING
----------------------------
A port mapping essentially says anytime that someone makes a request to a given port on your local network, take that request and automatically forward it to some port inside the container. So in other words, if anyone makes a request to local host 8080, take that request automatically forward it into the container on port 8080 where the node application can then receive it and process the request and eventually respond to it. Now, one thing that I wanna make sure is really clear right now from the get-go this is only talking about incoming requests.Your Docker container can by default make requests on its own behalf to the outside world.


To set up docker run with port mapping. We're gonna add on a dash P flag.

The syntax overall is docker, run, then dash P.
-----------------------------------------------
docker run -p 8080:8080 <image-name>


Then we're gonna specify that any incoming traffic on our local network to this port right here should be automatically forwarded onto this port inside the container right here.
And notice how there's a separation between these two ports or these two numbers of a colon.
We're gonna specify either the image ID or the image name. The one big thing to remember is that we have to specify it at runtime, not inside of the docker file.


# Specify a base image
FROM node:14-alpine

WORKDIR /usr/app

# Install some dependencies
COPY ./package.json ./  # To use the cache while building again
RUN npm install
COPY ./ ./

# Default Commands
CMD ["npm", "start"]



DOCKER COMPOSE
--------------
The purpose of Docker Compose is to essentially function as Docker CLI but allow you to kind of issue
multiple commands much more quickly.

Docker Compose automatically sets up networking between different services or different types of containers that we define inside of our docker compose file.

Separate CLI that gets installed along with the Docker.
Used to start up multiple containers at the same time
Automates some of the long-winded arguments that we were passing to 'docker run'


Purpose of Docker-compose make the docker run command much easier.

const client = redis.createClient({
    host: "redis-server", 
    port: 6379
})      

docker-compose.yml
------------------

version: "3"
services: 
  redis-server:
    image: "redis"
  node-app:
    build: .
    ports:
      - "4001:9091"



docker run myImage ---> docker-compose up


docker build .
docker run myImage ---> docker-compose up --build, docker-compose --build --nocache 


-d, --detach  Run container in background and print container ID
The -d flag starts up a container in detached mode.  Effectively, this means that output from the container will not be piped to your shell.  You can continue to run other commands while the container is still running.


Launch in Background
--------------------

docker-compose up -d

Stop Containers
---------------

docker-compose down

Status code - 0 (Successful Exit)
Status code - 1, 2, 3 etc.


Restart Policies
----------------
"no" = Never attempt to restart this . container if it stops or crashes
always = If this container stops *for any reason* always attempt to restart it
on-failure = Only restart if the container stops with an error code
unless-stopped = Always restart unless we(developers) forcibly stop it 	


docker-compose.yml
------------------
version: "3"
services: 
  redis-server:
    image: "redis"
  node-app:
  	restart: always
    build: .
    ports:
      - "4001:9091"


Container Status code
---------------------
docker-compose ps


npm run start --> Starts up a development server. For development use only. 
npm run build --> Runs test associated with the project.
npm run test  --> Builds a production version of the application.




Run Docker build command with custom Dockerfile name
----------------------------------------------------

docker build -f Dockerfile.dev .


When we use the -v flag we're essentially trying to say anytime that the container tries to access
something in the app directory, it's gonna reach back out of the container to the current or the present working directory on our local machine.



Bookmarking Docker Volumes
--------------------------

docker build -f Dockerfile.dev -t sauravr:frontend .

docker run -it -p 3000:3000 -v /home/node/app/node_modules -v /home/sauravr/frontend:/home/node/app sauravr:frontend


Run extra commands (Running Tests in a container - React App)
------------------
docker run -it <container-id> npm run test

Running Tests in interactive mode
---------------------------------
docker exec -it <container-id> npm run test


docker-compose.yml (with 2 containers - web and tests)
------------------
version: '3'
services:
  web: 
    stdin_open: true
    build: 
      context: .
      dockerfile: Dockerfile.dev
    ports: 
      - '3000:3000'
    volumes:
      - /app/node_modules
      - .:/app
  tests:
    build: 
      context: .
      dockerfile: Dockerfile.dev
    volumes:
      - /app/node_modules
      - .:/app
    command: ["npm", "run", "test"]

Command: docker-compose up --build


By default, the Nginx web server listens to all incoming connections on port 80. If you have installed an SSL certificate, then it will listen to all secure connections on port 443.


Docker Production Setup
-----------------------
Build Phase
...........
> Use node:16-alpine
> Copy package.json file
> Install Dependencies
> Run 'npm build run'

Run Phase
.........
> Use nginx
> Copy over the result of 'npm run build'
> Start nginx

/app/build -- contains the static files we built using npm run build

Dockerfile (For production with nginx image included)
----------

FROM node:16-alpine AS builder
WORKDIR '/app'
COPY package.json .
RUN npm install
COPY . .
RUN npm run build


FROM nginx
COPY --from=builder /app/build /usr/share/nginx/html


Commands 
--------
docker build .
docker run -p 8080:80 <Container-Id>